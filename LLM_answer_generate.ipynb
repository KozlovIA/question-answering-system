{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50352cdd",
   "metadata": {},
   "source": [
    "# Генерация ответов по ранее сгенерированным вопросам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e9d6163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Igorexy\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Igorexy\\anaconda3\\envs\\science_assistant\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from source.tinydb_manager import TinyDB_manager\n",
    "from source.chroma_manager import ChromaDBManager\n",
    "from source.llm_manager import LMStudioClient\n",
    "from prompt.prompts import QA_context\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, Any, List\n",
    "from tqdm import tqdm\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47de6417",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9804ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LANG = '_RUS'\n",
    "LANG = ''   # English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86fcdc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ImportantFiles\\Documents\\University\\Magic App\\source\\llm_manager.py:9: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  self.llm = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "# Путь к файлу с тестами необходимой модели эмбеддингов\n",
    "# RAG_result_path = 'benchmark/input_LLM/multi-qa-MiniLM-L6-cos-v1-embedding.json'\n",
    "# chroma_config_path = \"config/embedding/multi-qa-MiniLM-L6-cos-v1.yaml\"\n",
    "chroma_config_path = \"config/embedding/questions_gen.yaml\"\n",
    "# chroma_config_path = \"config/embedding/questions_rus.yaml\"\n",
    "\n",
    "# LLM_config_path = \"config/LLM/qwen2.5_7b_instruct.yaml\"\n",
    "# LLM_config_path = \"config/LLM/meta-llama-3.1-8b-instruct.yaml\"\n",
    "# LLM_config_path = \"config/LLM/gpt4chan-8b.yaml\"\n",
    "# LLM_config_path = \"config/LLM/mistral-7b-instruct-v0.3.yaml\"\n",
    "# LLM_config_path = \"config/LLM/qwen2.5-7b-instruct-1m.yaml\"\n",
    "# LLM_config_path = \"config/LLM/llama-3.2-3b-instruct.yaml\"\n",
    "# LLM_config_path = \"config/LLM/qwen3-1.7b.yaml\"\n",
    "# LLM_config_path = \"config/LLM/gemma-3-1b-it.yaml\"\n",
    "# LLM_config_path = \"config/LLM/deepseek-r1-distill-qwen-1.5b.yaml\"\n",
    "# LLM_config_path = \"config/LLM/phi-3.1-mini-128k-instruct@q4_k_m.yaml\"\n",
    "# LLM_config_path = \"config/LLM/phi-3.1-mini-128k-instruct@iq3_m.yaml\"\n",
    "LLM_config_path = \"config/LLM/deepseek-r1-0528-qwen3-8b.yaml\"\n",
    "\n",
    "LLM_config = LMStudioClient.load_config(LLM_config_path)\n",
    "\n",
    "LLM_NAME = LLM_config['model_name']\n",
    "\n",
    "result_path = f\"benchmark/output_LLM{LANG}/{LLM_NAME}.json\".replace('-', '_')\n",
    "\n",
    "chroma_manager = ChromaDBManager(chroma_config_path)\n",
    "tiny_manager = TinyDB_manager(result_path)\n",
    "\n",
    "llm_manager = LMStudioClient(LLM_config_path)\n",
    "\n",
    "# Считывание JSON-файла в словарь\n",
    "# with open(RAG_result_path, 'r', encoding='utf-8') as f:\n",
    "#     RAG_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ce1ba9",
   "metadata": {},
   "source": [
    "# Выбираем часть датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8186495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# len(RAG_data.keys())\n",
    "# random_50 = random.sample(list(RAG_data.keys()), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dab394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_keys = ['0105522v1',\n",
    " '2309.00201v2',\n",
    " '2409.08175v1',\n",
    " '2002.04991v1',\n",
    " '2402.06452v1',\n",
    " '0504056v1',\n",
    " '2010.14616v1',\n",
    " '1505.02965v2',\n",
    " '2405.03720v1',\n",
    " '2402.04453v1',\n",
    " '1104.4174v1',\n",
    " '2108.10078v1',\n",
    " '2306.13586v1',\n",
    " '2303.02715v1',\n",
    " '2111.08438v1',\n",
    " '2501.12927v1',\n",
    " '2102.02850v3',\n",
    " '2012.02526v2',\n",
    " '2110.01856v1',\n",
    " '2009.07708v1',\n",
    " '1511.05520v1',\n",
    " '2005.11394v1',\n",
    " '2106.08671v2',\n",
    " '1805.04825v1',\n",
    " '2502.07081v2',\n",
    " '2501.16247v1',\n",
    " '2302.02016v1',\n",
    " '1211.1127v1',\n",
    " '2501.06863v1',\n",
    " '1804.03313v1',\n",
    " '2004.02401v1',\n",
    " '2210.00770v1',\n",
    " '2305.11304v2',\n",
    " '2211.00176v1',\n",
    " '2305.10344v2',\n",
    " '2007.04446v1',\n",
    " '2008.09306v1',\n",
    " '2211.15869v1',\n",
    " '2006.02158v2',\n",
    " '1702.06794v1',\n",
    " '2209.15308v1',\n",
    " '1911.05640v2',\n",
    " '2206.06828v1',\n",
    " '2010.06026v1',\n",
    " '2007.04911v2',\n",
    " '2208.10651v1',\n",
    " '1205.1938v1',\n",
    " '2307.12343v1',\n",
    " '2405.09305v1',\n",
    " '2401.17200v1',\n",
    " '2312.06833v2',\n",
    " '2412.06481v1',\n",
    " '2108.11053v1',\n",
    " '2405.06323v1',\n",
    " '2005.13449v1',\n",
    " '2206.03950v3',\n",
    " '2311.10905v1',\n",
    " '1706.01109v2',\n",
    " '1808.05443v1',\n",
    " '1507.06923v1',\n",
    " '2203.14474v1',\n",
    " '1307.6275v1',\n",
    " '0910.4472v2',\n",
    " '2209.05559v6',\n",
    " '1811.07311v2',\n",
    " '2304.02781v1',\n",
    " '2212.08930v4',\n",
    " '1312.7118v1',\n",
    " '1402.5724v1',\n",
    " '2103.15593v1',\n",
    " '1805.00980v1',\n",
    " '1112.6281v1',\n",
    " '1806.01756v1',\n",
    " '2012.08044v2',\n",
    " '2211.08282v1',\n",
    " '2202.01214v1',\n",
    " '1701.00867v1',\n",
    " '2501.14940v3',\n",
    " '1301.3583v4',\n",
    " '1303.2104v1',\n",
    " '0909.2332v1',\n",
    " '1711.01739v1',\n",
    " '1808.10009v1',\n",
    " '2308.14478v1',\n",
    " '2110.04942v1',\n",
    " '1510.05684v2',\n",
    " '2306.08001v1',\n",
    " '2010.05522v1',\n",
    " '2010.08034v1',\n",
    " '2401.06793v1',\n",
    " '1506.01055v1',\n",
    " '1612.07993v1',\n",
    " '2106.12798v2',\n",
    " '2305.03360v1',\n",
    " '1212.0238v1',\n",
    " '0010231v1',\n",
    " '1104.4188v1',\n",
    " '2108.01468v1',\n",
    " '2101.06480v1',\n",
    " '2106.03259v1',\n",
    " '2006.11014v1',\n",
    " '2305.06063v2',\n",
    " '2410.12598v2',\n",
    " '2204.00778v1',\n",
    " '1607.07625v1',\n",
    " '2003.09873v1',\n",
    " '2304.12729v2',\n",
    " '1811.07579v2',\n",
    " '1408.3002v1',\n",
    " '1803.07418v1',\n",
    " '1412.2352v1',\n",
    " '2401.00974v1',\n",
    " '1904.10551v1',\n",
    " '2406.16106v1',\n",
    " '1702.07956v5',\n",
    " '1805.00559v1',\n",
    " '2004.07136v1',\n",
    " '2007.06559v2',\n",
    " '1805.02716v1',\n",
    " '2006.13307v1',\n",
    " '0012536v1',\n",
    " '1302.4207v1',\n",
    " '1910.12249v1',\n",
    " '1502.06254v2',\n",
    " '1710.06798v1',\n",
    " '2308.02870v1',\n",
    " '2005.03476v2',\n",
    " '2002.07971v2',\n",
    " '2210.08288v1',\n",
    " '2107.02331v1',\n",
    " '1910.12207v1',\n",
    " '1807.04739v1',\n",
    " '2003.08445v1',\n",
    " '1902.01544v1',\n",
    " '2106.13743v1',\n",
    " '1810.11363v1',\n",
    " '1805.11474v3',\n",
    " '2104.04375v1',\n",
    " '2409.18583v1',\n",
    " '2410.20161v1',\n",
    " '1705.04153v1',\n",
    " '2406.03348v1',\n",
    " '1908.06951v1',\n",
    " '1609.01228v1',\n",
    " '2111.15258v1',\n",
    " '2411.01881v2',\n",
    " '1503.03168v1',\n",
    " '2309.00626v1',\n",
    " '1711.11008v1',\n",
    " '2304.02260v1',\n",
    " '1812.02897v3',\n",
    " '2012.03575v1',\n",
    " '2204.12244v1',\n",
    " '2502.08869v1',\n",
    " '1806.08874v1',\n",
    " '2005.09148v1',\n",
    " '2308.08682v1',\n",
    " '1703.02910v1',\n",
    " '2204.09021v1',\n",
    " '1902.07068v1',\n",
    " '2006.10562v4',\n",
    " '2008.01171v1',\n",
    " '1706.09796v3',\n",
    " '2001.09608v1',\n",
    " '2007.05035v1',\n",
    " '1104.4193v1',\n",
    " '0804.0099v1',\n",
    " '2408.09908v2',\n",
    " '1705.03921v1',\n",
    " '0501077v1',\n",
    " '1808.08111v1',\n",
    " '2308.11924v1',\n",
    " '1704.00405v2',\n",
    " '2006.04059v1',\n",
    " '2410.18950v1',\n",
    " '2007.02259v1',\n",
    " '1105.0522v1',\n",
    " '1902.06127v2',\n",
    " '1908.11215v1',\n",
    " '2005.00524v1',\n",
    " '1809.06995v1',\n",
    " '2309.06659v2',\n",
    " '2104.13386v1',\n",
    " '2304.13812v1',\n",
    " '2109.13233v1',\n",
    " '1706.07525v1',\n",
    " '2501.16374v2',\n",
    " '2305.10114v1',\n",
    " '1704.01664v1',\n",
    " '1710.08952v1',\n",
    " '1603.03719v1',\n",
    " '2210.11024v1',\n",
    " '2207.02763v1',\n",
    " '2101.05840v1',\n",
    " '2408.15452v1',\n",
    " '2302.02756v1',\n",
    " '2208.11873v1',\n",
    " '1709.05067v1',\n",
    " '2009.01564v2',\n",
    " '2209.03032v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56819d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_dict = {key: RAG_data[key] for key in selected_keys if key in RAG_data}\n",
    "\n",
    "# print(filtered_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1d10a9",
   "metadata": {},
   "source": [
    "# Получаем контекст"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8ddf61",
   "metadata": {},
   "source": [
    "## Прошлая версия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af750ec",
   "metadata": {},
   "source": [
    "#### функция полноценного теста с 2 вопросами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb5f51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_generate_answers_2_questions(\n",
    "    full_data: Dict[str, Any],\n",
    "    existing_answer: List[str],\n",
    "    chroma_manager,\n",
    "    llm_manager,\n",
    "    tiny_manager\n",
    "):\n",
    "    \"\"\"full_data: Dict[str, Any], - Словарь с вопросами\n",
    "    existing_answer: List[str],\n",
    "    chroma_manager,\n",
    "    llm_manager,\n",
    "    tiny_manager\"\"\"\n",
    "    all_chroma_ids = set(chroma_manager.get_all_ids())\n",
    "\n",
    "    for doc_id, questions in tqdm(full_data.items()):\n",
    "        if doc_id in existing_answer:\n",
    "            continue  # пропускаем, если уже есть ответ\n",
    "\n",
    "        result_record = {\"id\": doc_id, doc_id: {}}  # итоговая структура для tiny\n",
    "\n",
    "        for question_key, question_data in questions.items():\n",
    "            search_groups = question_data.get(\"search_ids\", [])\n",
    "            if not search_groups:\n",
    "                continue\n",
    "\n",
    "            # собираем все id из search_ids (обычно одна группа)\n",
    "            flat_ids = list({item for sublist in search_groups for item in sublist})\n",
    "\n",
    "            # фильтрация на всякий случай (если в Chroma нет документа)\n",
    "            filtered_ids = [sid for sid in flat_ids if sid in all_chroma_ids]\n",
    "\n",
    "            # достаем документы из Chroma\n",
    "            docs_by_id = chroma_manager.get_documents_by_ids(filtered_ids)\n",
    "\n",
    "            # объединяем документы в единый контекст\n",
    "            context = \"\\n\\n\".join(doc_info[\"document\"] for doc_info in docs_by_id.values())\n",
    "\n",
    "            # используем только первый найденный документ\n",
    "            # context = \"\"\n",
    "            # if filtered_ids:\n",
    "            #     first_id = filtered_ids[0]\n",
    "            #     doc_info = chroma_manager.get_documents_by_ids([first_id])\n",
    "            #     if doc_info and first_id in doc_info:\n",
    "            #         context = doc_info[first_id][\"document\"]\n",
    "\n",
    "            # Извлекаем вопрос\n",
    "            user_question = question_data.get(\"question\", '')\n",
    "\n",
    "            # формируем prompt \n",
    "            prompt = QA_context.SYSTEM_QA_SHORT.format(question=user_question, context=context)\n",
    "\n",
    "            # замер времени генерации\n",
    "            start_time = time.time()\n",
    "            llm_answer = llm_manager.post_completion(prompt)\n",
    "            end_time = time.time()\n",
    "\n",
    "            generation_time = round(end_time - start_time, 3)\n",
    "\n",
    "            # обновляем вопрос\n",
    "            enriched_question = question_data.copy()\n",
    "            enriched_question[\"context\"] = context\n",
    "            enriched_question[\"answer_llm\"] = llm_answer\n",
    "            enriched_question[\"generation_time\"] = generation_time\n",
    "\n",
    "            result_record[doc_id][question_key] = enriched_question\n",
    "            break\n",
    "        # сохраняем результат\n",
    "        tiny_manager.save_result(result_record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad8ab39",
   "metadata": {},
   "source": [
    "#### Функция теста с 1 вопросом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e1db2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Логирование в файл\n",
    "logging.basicConfig(\n",
    "    filename='log/llm_test.log',\n",
    "    filemode='a',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def process_and_generate_answers(data: Dict[str, Any], \n",
    "                      existing_answer, \n",
    "                      chroma_manager, \n",
    "                      llm_manager, \n",
    "                      tiny_manager):\n",
    "    try:\n",
    "        all_ids = set(chroma_manager.get_all_ids())\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Ошибка при получении всех ID из Chroma: {e}\")\n",
    "        return\n",
    "\n",
    "    logger.info(f\"Всего документов в базе: {len(data)}\")\n",
    "\n",
    "    for doc_id in tqdm(data.keys(), desc=\"Обработка документов\"):\n",
    "        if doc_id in existing_answer:\n",
    "            continue\n",
    "\n",
    "        questions = data.get(doc_id, {})\n",
    "        question_data = questions.get(\"question_1\")\n",
    "        if not question_data:\n",
    "            logger.warning(f\"В документе {doc_id} отсутствует question_1.\")\n",
    "            continue\n",
    "\n",
    "        question_text = question_data[\"question\"]\n",
    "        search_ids_nested = question_data.get(\"search_ids\", [])\n",
    "\n",
    "        # Извлекаем только первый ID из первого списка\n",
    "        if not search_ids_nested or not search_ids_nested[0]:\n",
    "            logger.warning(f\"В {doc_id} пустой search_ids.\")\n",
    "            continue\n",
    "\n",
    "        first_related_id = search_ids_nested[0][0]\n",
    "\n",
    "        if first_related_id not in all_ids:\n",
    "            logger.warning(f\"Документ {first_related_id} из search_ids не найден в Chroma.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            document_entry = chroma_manager.get_documents_by_ids([first_related_id])\n",
    "            document_text = document_entry.get(first_related_id, {}).get(\"document\", \"\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Ошибка при получении документа {first_related_id} для {doc_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if not document_text:\n",
    "            logger.warning(f\"Пустой документ для {first_related_id}\")\n",
    "            continue\n",
    "\n",
    "        # Формируем промпт\n",
    "        try:\n",
    "            prompt = QA_context.SYSTEM_QA_SHORT.format(\n",
    "                question=question_text,\n",
    "                context=document_text\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Ошибка при форматировании промпта для {doc_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            answer_llm = llm_manager.post_completion(prompt)\n",
    "            generation_time = time.time() - start_time\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Ошибка при генерации ответа LLM для {doc_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        result_record = {\n",
    "            \"id\": doc_id,\n",
    "            \"question_1\": {\n",
    "                **question_data,\n",
    "                \"answer_llm\": answer_llm,\n",
    "                \"generation_time\": generation_time\n",
    "            }\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            tiny_manager.save_result(record=result_record)\n",
    "            logger.info(f\"Успешно сохранён результат для {doc_id}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Ошибка при сохранении результата для {doc_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6767bdf3",
   "metadata": {},
   "source": [
    "## функция теста с 1 вопросом без RAG поиска  \n",
    "Последняя актуальная версия для тестов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b08d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Настройка логирования\n",
    "logging.basicConfig(\n",
    "    filename='log/llm_generation.log',\n",
    "    filemode='a',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def process_and_generate_answers_latest(question_ids_list, \n",
    "                                 existing_answer, \n",
    "                                 chroma_manager, \n",
    "                                 llm_manager, \n",
    "                                 tiny_manager):\n",
    "    \"\"\"Если question_ids_list = 'all', то все документы, иначе переменная ожидает список ids\"\"\"\n",
    "    try:\n",
    "        if question_ids_list == 'all':\n",
    "            question_ids_list = chroma_manager.get_all_ids()\n",
    "        all_docs = chroma_manager.get_documents_by_ids(question_ids_list)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Ошибка при извлечении документов из Chroma: {e}\")\n",
    "        return\n",
    "\n",
    "    for doc_id in tqdm(question_ids_list, desc=\"Генерация ответов\"):\n",
    "        if doc_id in existing_answer:\n",
    "            logger.info(f\"Пропущен {doc_id} — уже существует.\")\n",
    "            continue\n",
    "\n",
    "        doc_entry = all_docs.get(doc_id)\n",
    "        if not doc_entry:\n",
    "            logger.warning(f\"Документ {doc_id} не найден в Chroma.\")\n",
    "            continue\n",
    "\n",
    "        metadata = doc_entry.get(\"metadata\", {})\n",
    "        document_text = doc_entry.get(\"document\", \"\")\n",
    "        \n",
    "        question_data = eval(metadata.get(\"questions\"))\n",
    "        question_1 = question_data.get(\"question_1\")\n",
    "        answer_1 = question_data.get(\"answer_1\")\n",
    "        if not question_1:\n",
    "            logger.warning(f\"В метаданных документа {doc_id} нет question_1.\")\n",
    "            continue\n",
    "\n",
    "        question_text = question_1\n",
    "        answer_text = answer_1\n",
    "        if not question_text:\n",
    "            logger.warning(f\"Вопрос отсутствует в question_1 для {doc_id}.\")\n",
    "            continue\n",
    "\n",
    "        if not document_text:\n",
    "            logger.warning(f\"Пустой текст документа для {doc_id}.\")\n",
    "            continue\n",
    "\n",
    "        # Формируем промпт\n",
    "        try:\n",
    "            if LANG == '_RUS':\n",
    "                prompt = QA_context.SYSTEM_QA_SHORT_RUS.format(\n",
    "                    question=question_text,\n",
    "                    context=document_text\n",
    "                )\n",
    "            else:\n",
    "                prompt = QA_context.SYSTEM_QA_SHORT.format(\n",
    "                    question=question_text,\n",
    "                    context=document_text\n",
    "                )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Ошибка при создании промпта для {doc_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Генерация ответа и замер времени\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            answer_llm = llm_manager.post_completion(prompt)\n",
    "            generation_time = time.time() - start_time\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Ошибка генерации LLM-ответа для {doc_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        result_record = {\n",
    "            \"id\": doc_id,\n",
    "            \"question_1\": {\n",
    "                \"question\": question_text,\n",
    "                \"answer\": answer_text,\n",
    "                \"answer_llm\": answer_llm,\n",
    "                \"generation_time\": generation_time\n",
    "            }\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            tiny_manager.save_result(record=result_record)\n",
    "            logger.info(f\"Успешно сохранён результат для \\n{result_record}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Ошибка при сохранении результата для {doc_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c57dd48",
   "metadata": {},
   "source": [
    "### Проверка наличия вопросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd846454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_answer = []\n",
    "\n",
    "if tiny_manager.count() > 0:\n",
    "    existing_answer = tiny_manager.get_all_ids()\n",
    "len(existing_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357ce1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Генерация ответов:  10%|▉         | 19/200 [08:02<2:03:06, 40.81s/it]"
     ]
    }
   ],
   "source": [
    "process_and_generate_answers_latest(#question_ids_list='all', \n",
    "                                    question_ids_list=selected_keys, \n",
    "                             existing_answer=existing_answer,\n",
    "                             chroma_manager=chroma_manager,\n",
    "                             llm_manager=llm_manager,\n",
    "                             tiny_manager=tiny_manager\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a00838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "science_assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
