{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Файл создания файлов для расчета RAG метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Igorexy\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Igorexy\\anaconda3\\envs\\science_assistant\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from source.chroma_manager import ChromaDBManager, CustomEmbeddingFunction\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import sys\n",
    "import json \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG_PATH = \"config/embedding/all-MiniLM-L6-v2.yaml\"\n",
    "# CONFIG_PATH = \"config/embedding/all-mpnet-base-v2.yaml\"\n",
    "# CONFIG_PATH = \"config/embedding/paraphrase-multilingual-MiniLM-L12-v2.yaml\"\n",
    "# CONFIG_PATH = \"config/embedding/multi-qa-mpnet-base-dot-v1.yaml\"\n",
    "# CONFIG_PATH = \"config/embedding/LaBSE.yaml\"\n",
    "# CONFIG_PATH = \"config/embedding/distiluse-base-multilingual-cased-v1.yaml\"\n",
    "# CONFIG_PATH = \"config/embedding/msmarco-distilbert-base-v4.yaml\"\n",
    "# CONFIG_PATH = \"config/embedding/multi-qa-MiniLM-L6-cos-v1.yaml\"\n",
    "# CONFIG_PATH = \"config/embedding/paraphrase-multilingual-mpnet-base-v2.yaml\"\n",
    "# CONFIG_PATH = \"config/embedding/stsb-xlm-r-multilingual.yaml\"\n",
    "# CONFIG_PATH = \"config/embedding/gtr-t5-large.yaml\"\n",
    "# CONFIG_PATH = \"config/embedding/e5-large-v2.yaml\"\n",
    "CONFIG_PATH = \"config/embedding/multilingual-e5-large.yaml\"\n",
    "\n",
    "config_path_question = \"config/embedding/questions_gen.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(CONFIG_PATH, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "CHROMA_PATH = config[\"chroma_path\"]\n",
    "COLLECTION_NAME = config[\"collection_name\"]\n",
    "MODEL_NAME = config[\"model_name\"]\n",
    "\n",
    "with open(config_path_question, \"r\") as file:\n",
    "    config_question_db = yaml.safe_load(file)\n",
    "\n",
    "CHROMA_PATH_QUESTION = config_question_db[\"chroma_path\"]\n",
    "COLLECTION_NAME_QUESTION = config_question_db[\"collection_name\"]\n",
    "MODEL_NAME_QUESTION = config_question_db[\"model_name\"]\n",
    "\n",
    "\n",
    "# Создаём менеджер с кастомной функцией эмбеддингов\n",
    "embedding_function = CustomEmbeddingFunction(model_name=MODEL_NAME)\n",
    "\n",
    "# Инициализируем менеджер с кастомными эмбеддингами\n",
    "model_chroma = ChromaDBManager(CONFIG_PATH)\n",
    "\n",
    "# Инициализируем менеджер с вопросами\n",
    "questions_chroma = ChromaDBManager(config_path_question)\n",
    "\n",
    "# Извлечение всех документов\n",
    "all_documents = questions_chroma.collection.get()\n",
    "doc_ids = all_documents.get(\"ids\", [])\n",
    "doc_metadata = all_documents.get(\"metadatas\", [])\n",
    "len(doc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_ids_batch = doc_ids\n",
    "# doc_metadata_batch = doc_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "векторный поиск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "436it [02:38,  2.75it/s]\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "\n",
    "# Прогон идет по БД с вопросами\n",
    "for doc_id, metadata in tqdm(zip(doc_ids, doc_metadata)): \n",
    "\n",
    "    question_1 = eval(metadata['questions'])['question_1']\n",
    "    question_2 = eval(metadata['questions'])['question_2']\n",
    "    answer_1 = eval(metadata['questions'])['answer_1']\n",
    "    answer_2 = eval(metadata['questions'])['answer_2']\n",
    "    query_results_1 = model_chroma.query(question_1, n_results=3)\n",
    "    query_results_2 = model_chroma.query(question_2, n_results=3)\n",
    "    \n",
    "    position_1, position_2 = False, False\n",
    "\n",
    "    validation_1 = doc_id in query_results_1['ids'][0]\n",
    "    if validation_1:\n",
    "        position_1 = query_results_1['ids'][0].index(doc_id)\n",
    "\n",
    "    validation_2 = doc_id in query_results_2['ids'][0]\n",
    "    if validation_2:\n",
    "        position_2 = query_results_2['ids'][0].index(doc_id)\n",
    "    \n",
    "    temp_res = {\n",
    "        doc_id: {\n",
    "            \"question_1\": {\n",
    "                    \"search_ids\": query_results_1['ids'],\n",
    "                    \"validation\": validation_1,\n",
    "                    \"position\": position_1,\n",
    "                    \"question\": question_1,\n",
    "                    \"answer\": answer_1,\n",
    "                            },\n",
    "            \"question_2\": {\n",
    "                    \"search_ids\": query_results_2['ids'],\n",
    "                    \"validation\": validation_2,\n",
    "                    \"position\": position_2,\n",
    "                    \"question\": question_2,\n",
    "                    \"answer\": answer_2,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    result.update(temp_res)\n",
    "\n",
    "output_filemane = f\"benchmark/output_RAG/{COLLECTION_NAME}.json\"\n",
    "\n",
    "with open(output_filemane, \"w\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    json.dump(result, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Расчет метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark.RAG_benchmark import VectorSearchMetrics\n",
    "\n",
    "filename = f\"benchmark/output_RAG/{COLLECTION_NAME}\"\n",
    "with open(f\"{filename}.json\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)  # Преобразование JSON в словарь\n",
    "\n",
    "bench = VectorSearchMetrics(data)\n",
    "metrics = bench.run()\n",
    "\n",
    "df = pd.DataFrame(list(metrics.items()), columns=[\"metric\", \"value\"]).to_excel(f\"{filename}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Составление единой таблицы сравнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Путь к папке с Excel файлами\n",
    "folder_path = r'benchmark\\output_RAG'\n",
    "\n",
    "# Список для хранения данных\n",
    "data = []\n",
    "\n",
    "# Перебираем все файлы в папке\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        # Полный путь к файлу\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Читаем таблицу из файла\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Получаем имя модели из имени файла (без расширения)\n",
    "        model_name = os.path.splitext(filename)[0].replace(\"-embedding\", '')\n",
    "        \n",
    "        # Добавляем столбец с названием модели\n",
    "        df['Model'] = model_name\n",
    "        \n",
    "        # Добавляем данные в общий список\n",
    "        data.append(df)\n",
    "\n",
    "# Объединяем все данные в одну таблицу\n",
    "result_df = pd.concat(data, ignore_index=True)\n",
    "\n",
    "# Переводим данные в удобный формат для сравнения\n",
    "pivot_df = result_df.pivot(index='metric', columns='Model', values='value')\n",
    "\n",
    "# Сортируем и меняем порядок индексов\n",
    "pivot_df = pivot_df.T.sort_values(\"Precision\", ascending=False).T.reindex([\"Precision\", \"Adjusted Score\", \"MRR\", \"First position accuracy\"])\n",
    "\n",
    "# Сохраняем итоговую таблицу в новый Excel файл\n",
    "pivot_df.to_excel('benchmark/comparison_models.xlsx')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "science_assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
