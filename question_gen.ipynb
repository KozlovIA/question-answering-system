{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Igorexy\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Igorexy\\anaconda3\\envs\\science_assistant\\Lib\\site-packages\\keras\\losses.py:2664: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ImportantFiles\\Documents\\University\\Magic App\\source\\llm_manager.py:9: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  self.llm = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "from source.chroma_manager import ChromaDBManager, CustomEmbeddingFunction\n",
    "from source.llm_manager import LMStudioClient\n",
    "from prompt.prompts import QuestionsToDoc\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import json\n",
    "import logging\n",
    "\n",
    "DB_CONFIG = LMStudioClient.load_config(\"config/embedding/questions_gen.yaml\")\n",
    "MODEL_CONFIG_PATH = \"config/model_question_gen.yaml\"\n",
    "\n",
    "logging.basicConfig(filename=\"log/question_gen.log\", level=logging.ERROR, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "\n",
    "# Инициализация менеджеров\n",
    "source_chroma = ChromaDBManager(\n",
    "    storage_path=DB_CONFIG[\"chroma_path\"],\n",
    "    collection_name=DB_CONFIG[\"collection_name\"],\n",
    "    embedding_function=CustomEmbeddingFunction(DB_CONFIG[\"model_name\"])\n",
    ")\n",
    "\n",
    "llm = LMStudioClient(MODEL_CONFIG_PATH)  # URL настроить под свой сервер\n",
    "\n",
    "# Извлечение всех документов\n",
    "all_documents = source_chroma.collection.get()\n",
    "doc_ids = all_documents.get(\"ids\", [])\n",
    "doc_texts = all_documents.get(\"documents\", [])\n",
    "doc_metadata = all_documents.get(\"metadatas\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "549"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_ids_batch = doc_ids[300:]\n",
    "# doc_texts_batch = doc_texts[300:]\n",
    "# doc_metadata_batch = doc_metadata[300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_str_to_dict(s: str):\n",
    "    \"\"\"\n",
    "    Преобразует строку в словарь, если возможно.\n",
    "    В противном случае возвращает False.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = ast.literal_eval(s)\n",
    "        if isinstance(result, dict):\n",
    "            return result\n",
    "        return False\n",
    "    except (ValueError, SyntaxError):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Список ids где в метадате отсутвуют вопросы\n",
    "ids_to_generate = []\n",
    "for ids, metadatas in zip(doc_ids, doc_metadata):\n",
    "    if 'questions' not in list(metadatas.keys()):\n",
    "        ids_to_generate.append(ids)\n",
    "len(ids_to_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [11:07, 34.07s/it]<unknown>:3: SyntaxWarning: invalid escape sequence '\\('\n",
      "<unknown>:5: SyntaxWarning: invalid escape sequence '\\('\n",
      "28it [15:38, 44.38s/it]<unknown>:3: SyntaxWarning: invalid escape sequence '\\('\n",
      "<unknown>:5: SyntaxWarning: invalid escape sequence '\\('\n",
      "29it [16:26, 45.70s/it]<unknown>:3: SyntaxWarning: invalid escape sequence '\\('\n",
      "<unknown>:5: SyntaxWarning: invalid escape sequence '\\('\n",
      "134it [1:08:51, 26.00s/it]<unknown>:5: SyntaxWarning: invalid escape sequence '\\('\n",
      "145it [1:31:32, 52.81s/it] <unknown>:5: SyntaxWarning: invalid escape sequence '\\('\n",
      "152it [1:35:32, 35.53s/it]<unknown>:3: SyntaxWarning: invalid escape sequence '\\('\n",
      "<unknown>:5: SyntaxWarning: invalid escape sequence '\\('\n",
      "154it [1:36:08, 27.08s/it]<unknown>:5: SyntaxWarning: invalid escape sequence '\\('\n",
      "157it [1:38:07, 35.40s/it]<unknown>:2: SyntaxWarning: invalid escape sequence '\\('\n",
      "<unknown>:3: SyntaxWarning: invalid escape sequence '\\('\n",
      "<unknown>:4: SyntaxWarning: invalid escape sequence '\\('\n",
      "<unknown>:5: SyntaxWarning: invalid escape sequence '\\('\n",
      "160it [1:48:51, 196.81s/it]<unknown>:3: SyntaxWarning: invalid escape sequence '\\('\n",
      "177it [1:59:54, 32.42s/it] <unknown>:5: SyntaxWarning: invalid escape sequence '\\('\n",
      "549it [3:11:58, 20.98s/it] \n"
     ]
    }
   ],
   "source": [
    "for doc_id, doc_text, metadata in tqdm(zip(doc_ids, doc_texts, doc_metadata)):\n",
    "    if doc_id in ids_to_generate:\n",
    "        # Генерация вопросов через LLM\n",
    "        prompt = QuestionsToDoc.QUESTION_FORMATION.format(document=doc_text)\n",
    "        # print(repr(prompt))  # Выведет строку в raw-формате\n",
    "        questions = llm.post_completion(user_input=prompt)\n",
    "        llm.clear_context() # очищаем контекст\n",
    "        questions_dict = safe_str_to_dict(questions)\n",
    "        if questions_dict == False:\n",
    "            prompt = QuestionsToDoc.CORRECTING_DICKTIONARY.format(input=questions)\n",
    "            questions = llm.post_completion(user_input=prompt)\n",
    "            llm.clear_context() # очищаем контекст\n",
    "            questions_dict = safe_str_to_dict(questions)\n",
    "            if questions_dict == False:\n",
    "                print(\"Словарь не сгенерирован\")\n",
    "                print(questions)\n",
    "                logging.error(f\" doc_id={doc_id}: questions_dict={questions}\")\n",
    "                continue\n",
    "            \n",
    "        # Обновление метаданных\n",
    "        # print(\"Успешно\")\n",
    "        # print(questions_dict)\n",
    "        metadata[\"questions\"] = json.dumps(questions_dict)\n",
    "        source_chroma.update_document(document_id=doc_id, new_text=doc_text, new_metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "science_assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
