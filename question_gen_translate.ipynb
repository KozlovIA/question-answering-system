{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "791c1efd",
   "metadata": {},
   "source": [
    "# Перевод ранее сгенерированных вопросов на русский язык"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8555edd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Igorexy\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Igorexy\\anaconda3\\envs\\science_assistant\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ImportantFiles\\Documents\\University\\Magic App\\source\\llm_manager.py:9: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  self.llm = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "from source.chroma_manager import ChromaDBManager, CustomEmbeddingFunction\n",
    "from source.llm_manager import LMStudioClient\n",
    "from prompt.prompts import QuestionsToDoc\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import json\n",
    "import logging\n",
    "\n",
    "DB_ENG_CONFIG_PATH = \"config/embedding/questions_gen.yaml\"\n",
    "DB_RUS_CONFIG_PATH = \"config/embedding/questions_rus.yaml\"\n",
    "MODEL_CONFIG_PATH = \"config/model_question_gen.yaml\"\n",
    "\n",
    "\n",
    "logging.basicConfig(filename=\"log/question_gen.log\", level=logging.ERROR, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "\n",
    "# Инициализация менеджеров\n",
    "eng_chroma = ChromaDBManager(DB_ENG_CONFIG_PATH)\n",
    "rus_chroma = ChromaDBManager(DB_RUS_CONFIG_PATH)\n",
    "\n",
    "llm = LMStudioClient(MODEL_CONFIG_PATH)  # URL настроить под свой сервер\n",
    "\n",
    "# Извлечение всех документов\n",
    "all_documents = eng_chroma.collection.get()\n",
    "doc_ids = all_documents.get(\"ids\", [])\n",
    "doc_texts = all_documents.get(\"documents\", [])\n",
    "doc_metadata = all_documents.get(\"metadatas\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d824fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_str_to_dict(s: str):\n",
    "    \"\"\"\n",
    "    Преобразует строку в словарь, если возможно.\n",
    "    В противном случае возвращает False.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = ast.literal_eval(s)\n",
    "        if isinstance(result, dict):\n",
    "            return result\n",
    "        return False\n",
    "    except (ValueError, SyntaxError):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9929a728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Список ids где в метадате отсутвуют вопросы\n",
    "rus_collection = rus_chroma.collection.get()\n",
    "rus_ids = rus_collection.get(\"ids\", [])\n",
    "ids_to_generate = [x for x in doc_ids if x not in rus_ids]\n",
    "len(ids_to_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "999a4678",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_generate = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01506f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:56, 56.06s/it]"
     ]
    }
   ],
   "source": [
    "for doc_id, doc_text, metadata in tqdm(zip(doc_ids, doc_texts, doc_metadata)):\n",
    "    if doc_id not in ids_to_generate:\n",
    "        questions_eng = eval(metadata['questions'])\n",
    "        \n",
    "        question_1 = questions_eng['question_1']\n",
    "        answer_1 = questions_eng['answer_1']\n",
    "\n",
    "        # Генерация вопросов через LLM\n",
    "        prompt = QuestionsToDoc.TRANSLATE_TO_RUSSIAN.format(\n",
    "            question=question_1,\n",
    "            answer=answer_1,\n",
    "            doc=doc_text\n",
    "        )\n",
    "        # print(repr(prompt))  # Выведет строку в raw-формате\n",
    "        questions = llm.post_completion(user_input=prompt)\n",
    "        llm.clear_context() # очищаем контекст\n",
    "        questions_dict = safe_str_to_dict(questions)\n",
    "        if questions_dict == False:\n",
    "            prompt = QuestionsToDoc.CORRECTING_DICKTIONARY_ONE_QUESTION.format(input=questions)\n",
    "            questions = llm.post_completion(user_input=prompt)\n",
    "            llm.clear_context() # очищаем контекст\n",
    "            questions_dict = safe_str_to_dict(questions)\n",
    "            if questions_dict == False:\n",
    "                print(\"Словарь не сгенерирован\")\n",
    "                print(questions)\n",
    "                logging.error(f\"doc_id={doc_id}: questions_dict={questions}\")\n",
    "                continue\n",
    "            \n",
    "        # Обновление метаданных\n",
    "        # print(\"Успешно\")\n",
    "        # print(questions_dict)\n",
    "        metadata[\"questions\"] = json.dumps(questions_dict)\n",
    "        rus_chroma.insert_document(document_id=doc_id, document_text=doc_text, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed76d08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "science_assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
